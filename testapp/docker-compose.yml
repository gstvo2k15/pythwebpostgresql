version: '3.8'

services:
  app1:
    build:
      context: ./app
    environment:
      - FLASK_APP=app.py
    ports:
      - "5001:5000"
    depends_on:
      - db
    networks:
      - monitoring_net
    restart: always
    container_name: app1

  app2:
    build:
      context: ./app
    environment:
      - FLASK_APP=app.py
    ports:
      - "5002:5000"
    depends_on:
      - db
    networks:
      - monitoring_net
    restart: always
    container_name: app2

  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"
    networks:
      - monitoring_net
    restart: always
    container_name: db

  nginx:
    build:
      context: ./nginx
    ports:
      - "80:80"
    depends_on:
      - app1
      - app2
    networks:
      - monitoring_net
    restart: always
    container_name: nginx

  prometheus:
    image: prom/prometheus:v2.52.0
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - monitoring_net
    restart: always
    container_name: prometheus

  loki:
    image: grafana/loki:2.9.2
    ports:
      - "3100:3100"
    networks:
      - monitoring_net
    command: -config.file=/etc/loki/local-config.yaml
    container_name: loki  

  promtail:
    image: grafana/promtail:2.9.2
    volumes:
      - ./promtail-local-config.yaml:/etc/promtail/config.yaml:ro
    command: -config.file=/etc/promtail/config.yaml
    networks:
      - monitoring_net
    container_name: promtail    

  grafana:
    image: grafana/grafana:10.1.10
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    ports:
      - "3000:3000"
    networks:
      - monitoring_net
    restart: always
    container_name: grafana

  cadvisor:
    image: secureimages/cadvisor:0.47.2-alpine-3.18.2
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - "8080:8080"
    privileged: true
    networks:
      - monitoring_net
    restart: always
    container_name: cadvisor

  node_exporter:
    image: prom/node-exporter:v1.8.0
    ports:
      - "9100:9100"
    networks:
      - monitoring_net
    restart: always
    container_name: node_exporter

  blackbox_exporter:
    image: prom/blackbox-exporter:v0.25.0
    ports:
      - "9115:9115"
    networks:
      - monitoring_net
    restart: always
    container_name: blackbox_exporter

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.4.0
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    networks:
      - monitoring_net
    restart: always
    container_name: elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.4.0
    environment:
      ELASTICSEARCH_HOSTS: 'http://elasticsearch:9200'
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - monitoring_net
    restart: always
    container_name: kibana

  kafka:
    image: bitnami/kafka:3.1.0
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"
    networks:
      - monitoring_net
    restart: always
    container_name: kafka

  zookeeper:
    image: bitnami/zookeeper:3.7.0
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks:
      - monitoring_net
    restart: always
    container_name: zookeeper

  kong:
    image: kong:2.8
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: "/usr/local/kong/declarative/kong.yml"
    volumes:
      - ./kong/kong.yml:/usr/local/kong/declarative/kong.yml
    ports:
      - "8000:8000"
      - "8443:8443"
      - "8001:8001"
      - "8444:8444"
    networks:
      - monitoring_net
    restart: always
    container_name: kong

  lint:
    build:
      context: .
      dockerfile: Dockerfile.lint
    networks:
      - monitoring_net
    container_name: lint
    restart: "no"

  sonarqube:
    build:
      context: ./sonarqube
    ports:
      - "9000:9000"
    networks:
      - monitoring_net
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    environment:
      - sonar.secretKeyPath=/etc/sonarqube/sonar_token.txt
    volumes:
      - ./sonar-scanner/sonar_token.txt:/etc/sonarqube/sonar_token.txt:ro
    container_name: sonarqube

  sonar-scanner:
    build:
      context: ./sonar-scanner
    networks:
      - monitoring_net
    container_name: sonar-scanner
    depends_on:
      sonarqube:
        condition: service_healthy
    environment:
      - SONAR_HOST_URL=http://sonarqube:9000
      - SONAR_LOGIN=m/klUDNemJHMhjfGjX1PTIH/FLuZcn+xAbNPQmHrOxA=
    restart: "no"
    #command: sonar-scanner -Dsonar.host.url=http://sonarqube:9000 -Dsonar.login=your_login_token
      
networks:
  monitoring_net:

